function [ output ] = decode_linearclassifier ( signal, t, trials, params)
% % decode_linearclassifier %
%PURPOSE:   Decoding with linear classifier
%AUTHORS:   AC Kwan 170522
%
%INPUT ARGUMENTS
%   signal:         time-series signal (time x cells)
%   t:              time points corresponding to the signal
%   trials:         the structure generated by flex_getTrialMasks().
%
%   params.trigEvent:     event, dummy-coded (e.g., for choice, left=-1, right=1)
%   params.trigTime:      the event times
%   params.traintest_fieldname:    the subset of trials used to construct and test classifier (x-fold cross-validation), e.g. hit trials
%   params.addtest_fieldname:      other, orthogonal subset of trials used to also test classifier, e.g. error trials
%           addtest need to be non-overlapping with the traintest trials,
%           otehrwise we are not doing cross-validation correctly
%   params.window:  the time window around which to align signal
%   params.nBack:   decode not only the current trial's event, but also
%                   preceding trial's events up to nBack
%
%   params.numRep:  number of bootstrap repeats
%   params.frac:    fraction of trials used to construct the classifier, the rest is for testing

%OUTPUT ARGUMENTS
%   output:         structure containing decoding analysis results
%
% To plot the output, use plot_decode().

if isfield(params,'addtest_fieldname')
    numAddTest = numel(params.addtest_fieldname);  %number of additional conditions to test
else
    numAddTest = 0;
end

if ~isfield(params,'nBack')
    params.nBack = 0;
end
    
trial_traintest = getAnyMask(trials,params.traintest_fieldname);
output.fieldname = params.traintest_fieldname;
for j=1:numAddTest
    trial_addTest{j} = getAnyMask(trials,params.addtest_fieldname{j});
    output.fieldname_addTest{j} = params.addtest_fieldname{j};
end

%% interpolate signal, finer time bins here allows finer alignment to events

nCell = size(signal,2);

window=params.window;

% interpolate the signal to a finer time scale
interdt=0.05;
intert=[t(1):interdt:t(end)]';
intersig=interp1(t,signal,intert);

% align signal to the event
% use window slightly wider than the regression, so regression analysis
% won't run into the boundaries of this variable
[sigbyTrial, tbyTrial]=align_signal(intert,intersig,params.trigTime,[window(1)-1 window(end)+1]);

%% for decoding, set the coarser time bins
step_dur = nanmean(diff(window));
step_size = step_dur;       %if step size is step duration, then doing this in non-overlapping windows
output.decode_time = [window(1)+step_dur/2:step_size:window(end)-step_dur/2]';

%% constrcut linear classifier

corrPred=[];
corrPred_randsig=[];
corrPred_scram=[];
numTestTrial_addTest=[];
corrPred_addTest=[];
corrPred_addTest_randsig=[];
corrPred_addTest_scram=[];

for n = 0:1:params.nBack
    % restrict to the specified trial subset
    event_traintest = params.trigEvent(trial_traintest);  %the event, dummy-coded, e.g. left=-1, right=1
    trialnum_traintest = find(trial_traintest==1);        %IDs of the trials used 
    if n == 0   %use current trial's dF/F to decipher current trial's task event
        sigbyTrial_traintest = sigbyTrial(:,trial_traintest,:);  %the neural signal, e.g., dF/F
    else        %use current trial's dF/F to decipher past trial's task event
        sigbyTrial_traintest = sigbyTrial(:,[false(n,1); trial_traintest(1:end-n)],:);
    end
    
    % any NaN must be removed (signals in trials that do not fall under any category to be classified)
    badTrials = isnan(event_traintest);
    event_traintest = event_traintest(~badTrials);
    trialnum_traintest = trialnum_traintest(~badTrials);
    sigbyTrial_traintest = sigbyTrial_traintest(:,~badTrials,:);
    
    % if sigbyTrial has NaN, it should be removed, for example no signal prior to t=0 in first trial)
    badTrials = (sum(sum(isnan(sigbyTrial_traintest),3),1)>0)';
    event_traintest = event_traintest(~badTrials);
    trialnum_traintest = trialnum_traintest(~badTrials);
    sigbyTrial_traintest = sigbyTrial_traintest(:,~badTrials,:);
    
    % repeat the three prior steps for the additional test trials
    for j=1:numAddTest
        event_addTest{j} = params.trigEvent(trial_addTest{j});
        trialnum_addTest{j} = find(trial_addTest{j}==1);
        if n == 0   %use current trial's dF/F to decipher current trial's task event
            sigbyTrial_addTest{j} = sigbyTrial(:,trial_addTest{j},:);
        else        %use current trial's dF/F to decipher past trial's task event
            sigbyTrial_addTest{j} = sigbyTrial(:,[false(n,1); trial_addTest{j}(1:end-n)],:);
        end
        
        badTrials = isnan(event_addTest{j});
        event_addTest{j} = event_addTest{j}(~badTrials);
        trialnum_addTest{j} = trialnum_addTest{j}(~badTrials);
        sigbyTrial_addTest{j} = sigbyTrial_addTest{j}(:,~badTrials,:);
        
        badTrials = (sum(sum(isnan(sigbyTrial_addTest{j}),3),1)>0)';
        event_addTest{j} = event_addTest{j}(~badTrials);
        trialnum_addTest{j} = trialnum_addTest{j}(~badTrials);
        sigbyTrial_addTest{j} = sigbyTrial_addTest{j}(:,~badTrials,:);
    end
    
    %%
    
    for jj=1:numel(output.decode_time)  % each time step
        idx1=sum(tbyTrial<=(output.decode_time(jj)-step_dur/2));     %signal corresponding to current time step
        idx2=sum(tbyTrial<(output.decode_time(jj)+step_dur/2));
        if nCell > 1
            tempsig=squeeze(nanmean(sigbyTrial_traintest(idx1:idx2,:,:),1));       % signal is [event x cells]
            for j = 1:numAddTest
                tempsig_addTest{j}=squeeze(nanmean(sigbyTrial_addTest{j}(idx1:idx2,:,:),1));
            end
        else
            tempsig=nanmean(sigbyTrial_traintest(idx1:idx2,:),1)';                 % signal is [event x 1]
            for j = 1:numAddTest
                tempsig_addTest{j}=nanmean(sigbyTrial_addTest{j}(idx1:idx2,:),1)';
            end
        end
        
        for ll=1:params.numRep
            
            %use this subset of trials to construct classifier
            drawIndex=false(numel(event_traintest),1);
            drawnNum=randsample(numel(drawIndex),round(params.frac*numel(drawIndex)),'false'); %draw without replacement
            drawIndex(drawnNum)=true;
            
            LDAsig=tempsig(drawIndex,:);
            LDAoutcome=event_traintest(drawIndex);  %events used to train classifier
            
            %linear classifier / linear discriminant analysis
            testsig=tempsig(~drawIndex,:);
            testoutcome=event_traintest(~drawIndex);  %events used to test classifier
            outcomebyLDA=classify(testsig,LDAsig,LDAoutcome,'linear');
            corrPred(jj,ll,n+1)=sum(outcomebyLDA==testoutcome)/numel(outcomebyLDA);
            
            %control: construct linear classifier when activity is scrambled
            %(as if neurons were not recorded simultaneously)
            LDAsig_rand = nan(size(LDAsig));
            outcomeType = unique(LDAoutcome);
            for k = 1:nCell  %for each cell..
                for j = 1:numel(outcomeType) %for each outcome type..
                    idx = find(LDAoutcome == outcomeType(j));
                    randIdx = idx(randperm(numel(idx)));
                    LDAsig_rand(randIdx,k) = LDAsig(idx,k); %shuffle the trial-by-trial activity of this cell
                end
            end
            
            outcomebyLDA=classify(testsig,LDAsig_rand,LDAoutcome,'linear');
            corrPred_randsig(jj,ll,n+1)=sum(outcomebyLDA==testoutcome)/numel(outcomebyLDA);
            
            %control: construct linear classifier when task events are scrambled
            LDAoutcome_scram=LDAoutcome(randperm(numel(LDAoutcome))); %scramble event outcomes used to construct classifier
            
            outcomebyLDA_scram=classify(testsig,LDAsig,LDAoutcome_scram,'linear'); %use it to try to decode actual outcomes
            corrPred_scram(jj,ll,n+1)=sum(outcomebyLDA_scram==testoutcome)/numel(outcomebyLDA_scram);
            
            %apply same linear classifer to another trial subset (e.g. error trials)
            for j=1:numAddTest
                excludeSet = trialnum_traintest(drawIndex);  %ID of trials that were used to construct the classifier
                includeSet = setdiff(trialnum_addTest{j},excludeSet);  %make sure all the additional test trials exclude those trials used to construct the classifier
                includeIdx = ismember(trialnum_addTest{j},includeSet);
                
                numTestTrial_addTest{j}(jj,ll,n+1)=numel(includeIdx);     %how many trials were decoded
                
                testsig_addTest=tempsig_addTest{j}(includeIdx,:);   %no need to cross-validate, use all the include-set data to test classifier
                testoutcome_addTest=event_addTest{j}(includeIdx);
                outcomebyLDA=classify(testsig_addTest,LDAsig,LDAoutcome,'linear');
                corrPred_addTest{j}(jj,ll,n+1)=sum(outcomebyLDA==testoutcome_addTest)/numel(outcomebyLDA);
                
                outcomebyLDA=classify(testsig_addTest,LDAsig_rand,LDAoutcome,'linear');
                corrPred_addTest_randsig{j}(jj,ll,n+1)=sum(outcomebyLDA==testoutcome_addTest)/numel(outcomebyLDA);
                
                outcomebyLDA_scram=classify(testsig_addTest,LDAsig,LDAoutcome_scram,'linear'); %use it to try to decode actual error trials
                corrPred_addTest_scram{j}(jj,ll,n+1)=sum(outcomebyLDA_scram==testoutcome_addTest)/numel(outcomebyLDA_scram);
            end
        end
    end
end

output.numRepeat = params.numRep;

output.corrPred=corrPred;
output.corrPred_randsig=corrPred_randsig;
output.corrPred_scram=corrPred_scram;  %chance level performance of the classifier

output.numTestTrial_addTest=numTestTrial_addTest;

output.corrPred_addTest=corrPred_addTest;
output.corrPred_addTest_randsig=corrPred_addTest_randsig;
output.corrPred_addTest_scram=corrPred_addTest_scram;

end
